# Involution Without Exit
## Why Rising Productivity Is Colliding with the Disappearance of Human Subjectivity

## Part I — The concept

We are working harder, learning faster, and upgrading ourselves more aggressively than any generation before us — yet many of us feel increasingly replaceable. The more we compete, the less it seems to matter. This strange condition is not merely psychological; it reflects a deeper structural pattern.

In *The Operational Logic of Grassroots China*, this pattern is named “involution”: competition without structural transformation. In regions where agricultural technology advanced, the book shows, productivity rose but population grew faster, producing labor surpluses and collapsing incentives to innovate. Effort multiplied, yet nothing fundamentally changed. More work did not produce more freedom — only more pressure.

Analytically inverting the original argument, one might hypothesize that in regions with advanced information technology, slower population growth and labor scarcity create stronger incentives to develop labor-saving IT innovations. If so, those who specialize in IT may paradoxically accelerate their own structural risk of obsolescence, as technologies capable of substituting human labor emerge. The relentless cycle of “involution” thus may undermine its own participants, producing diminishing returns at the macro level.

The book also notes that advancements in communication technology reduce information asymmetry between central and local authorities, enhancing central oversight and diminishing local autonomy. This trend favors centralized governance as the optimal organizational form.

This observation invites reflection on the role of major tech conglomerates in China, such as Tencent, Alibaba, and ByteDance, which dominate market shares to an extent approaching monopoly. Meanwhile, mainland China restricts access to platforms like YouTube, imposing barriers that limit citizens’ comparative reference points with the outside world. Such restrictions likely influence patterns of internal competition and societal development.

China’s demographic challenges—including an aging population and declining birth rates—also intersect with the culture of internal competition. How these trends will reshape “involution” remains an open question.

This article does not aim to provide a definitive answer or a ready-made solution. Each person’s experience and position within these systems is different, and it would be dishonest to impose a one-size-fits-all prescription. Instead, I offer this piece as a record of my own thinking and inquiry. More precisely, it is an attempt to clarify one guiding question: “What kind of illusion am I refusing to participate in?” Readers who wish to reflect on this together are welcome to reach out and share their perspectives.

## Part II — The paradox

AI is accelerating transformations across industries, intensifying competition and social anxiety, which in turn exacerbate the phenomenon of “involution.”

- **AI intensifies competition.**  
AI threatens a large share of jobs, with many workers fearing displacement. Paradoxically, those creating AI tools may hasten their own obsolescence by enabling automation that substitutes human labor. This dynamic deepens competitive pressure without expanding meaningful opportunities, reinforcing involution.

- **Productivity rises.**  
Generative AI reduces task times and improves output quality, especially for lower-skilled workers, boosting overall labor productivity. Yet these gains often translate into intensified expectations rather than expanded agency, perpetuating a cycle where increased effort yields diminishing personal returns — a hallmark of involution.

- **Human relevance falls.**  
Despite productivity gains, AI adoption can slow experienced workers and erode job satisfaction, shifting humans into monitoring roles rather than creators. This displacement of judgment and responsibility fragments work meaning, illustrating how involution undermines human subjectivity in economic systems.

I recently experienced a related phenomenon during an internship. A colleague frequently used AI-generated content without critical evaluation or logical verification, leading to outputs that did not meet quality standards. This resulted in a need for substantial rework on my part. This experience illustrates a broader trend of judgment erosion and responsibility displacement in AI-mediated work. It highlights the critical role of human oversight in integrating AI outputs into coherent and meaningful products. (I share this reflection cautiously, mindful of potential professional sensitivities.)

## Part III — The empirical mirror

The following data should be understood as patterns that mirror the conceptual argument above.

### AI Job Growth: Beyond the Tech Sector

AI-related job postings have expanded beyond traditional software and high-tech firms into sectors such as healthcare, manufacturing, and finance. In Hong Kong SAR, despite a generally weaker job market with fewer roles posted, the share of AI-related job postings rose from 1.6% in 2023 to 1.9% in 2024, indicating sustained demand for AI skills. Similarly, in the US, AI job postings increased significantly over the same period, reflecting persistent demand despite broader market softness.

PwC’s 2025 Barometer reports that jobs with high AI exposure are growing 28% faster than those with low exposure. Roles involving “augmentation” (AI assisting humans) are increasing more rapidly than those susceptible to “automation” (AI replacing humans). Notably, over half of AI-related postings in 2025 target non-IT roles such as Solutions Architects and Product Managers, down from 61% in 2019. These trends suggest a complex labor market response consistent with involutionary pressures.

This pattern reflects intensified competition without expanded exit options or increased worker agency.

### Wage Polarization: The "Skill Premium" Gap

AI contributes to a “k-shaped” wage recovery, where high-skilled workers experience wage gains while middle- and low-skilled clerical workers face stagnation or decline. The IMF (2024–2025) warns of intra-bracket polarization: workers who effectively utilize AI see productivity and wage improvements, whereas others fall behind. Employers increasingly pay premiums—up to 23%—for roles combining AI proficiency with strategic decision-making. Meanwhile, clerical workers tend to be replaced rather than augmented, depressing wages in administrative sectors. This polarization reflects and reinforces involutionary dynamics.

This wage pattern demonstrates growing inequality and competitive stratification without structural mobility.

### Credential Inflation vs. Skills-Based Hiring

Despite rhetoric around “skills-based hiring,” the labor market exhibits credential inflation and a “Graduate Glut.” The Burning Glass Institute (2025) reports that AI is eliminating entry-level tasks, prompting employers to raise educational requirements for junior positions, often demanding postgraduate degrees or specialized AI certifications. Although over 1.1 million credentials exist, only about one in eight confer significant wage benefits, with high-value credentials concentrated in security clearances and cloud certifications combined with AI skills. This credential escalation reflects structural pressures characteristic of involution.

Credential inflation here signals escalating barriers to entry and competition without corresponding expansion of meaningful opportunities.

### Platform & Geographic Concentration

Geographic concentration of AI jobs is pronounced: a Brookings study (2025) finds that the Bay Area accounts for 13% of all U.S. AI-related postings, while London and the South East comprise 75% of AI office locations in the UK. The high capital costs of computing infrastructure create significant barriers to entry, concentrating power among a few dominant platforms (Amazon, Google, Microsoft, Meta). In China, tech giants like Tencent, Alibaba, and ByteDance serve as central coordinators in digital capitalism, influencing consumption, data flows, and economic integration. These structural concentrations exacerbate competitive pressures and limit systemic diversification, reinforcing involutionary tendencies.

This concentration amplifies competitive intensity while restricting exit and agency, deepening involution’s grip. 

## Part IV — The ontological shift

The core shift behind involution today is simple but profound: people are still working, but they are no longer needed as thinking subjects. In the past, having a job usually meant being responsible for decisions, judgment, and outcomes. Your work carried your name, your choices, and your accountability. In AI‑mediated systems, that link is weakening.

AI now produces drafts, plans, designs, and decisions at a speed no human can match. Humans are increasingly asked not to create, but to check, approve, and correct what machines generate. The role of the worker quietly changes from author to reviewer. What matters is no longer what you think, but whether you can validate what the system has already produced.

This changes the meaning of responsibility. When something goes right, credit flows to the system. When something goes wrong, blame falls on the human who approved it. Judgment becomes a thin layer of risk management rather than an act of understanding. People remain in the loop, but no longer at the center.

In this sense, involution is not just about competition or wages. It is about what kind of beings we are allowed to be inside our own workplaces. A system that only values speed, scale, and optimization slowly pushes out the space for human agency, turning workers into interchangeable operators of processes they do not truly control.

## Part V — The position (not solution)

This article does not offer a program or a policy. It offers a position.

That position begins with a refusal: to refuse to mistake optimization for progress, or efficiency for meaning. In a world where systems learn, adapt, and optimize faster than any human can, the central risk is not that people will disappear from work, but that they will remain inside it while no longer being needed as thinking, judging subjects.

To take a position, therefore, is not to argue that we should “slow down” or simply “embrace AI.” It is to insist on a more demanding question: under what conditions does a person remain a subject rather than a component? What kinds of work, education, and institutions preserve human agency instead of dissolving it into metrics, dashboards, and automated outputs?

Seen in this light, involution is not only an economic trap but an existential one. We are building systems that grow ever more powerful, while shrinking the space in which human judgment can matter. We are optimizing faster than we are learning how to live inside what we have built. To see this clearly is already a form of resistance.